# 实验记录

漏了两周的记录
现在开始写

# 2024年3月
## 21日
为了测试工作记忆长度，尝试了翻转和复制任务。<br>
用llama2-7b-chat试了，不进行微调的情况下，只进行few-shot<br>
翻转任务的情况很差，复制任务表现较好<br>
但是复制任务表现好也是有要求的<br>
~~1.不能使用<bos>和<eos>作为表示符，可能是因为他们在训练时有特殊的含义(好像也没有明显差异)~~<br>
~~2.fewshot数量要足够，大概四个，并不是越多样本效果就越好，看上去到达四个之后就变得随机起来了，或许序列本身也有影响<br>~~
3.或许可以只测后一半，前面一半相当于prompt的一部分，这样zero-shot的效果也挺好(其实前面一半也相当于很多个演示了)<br>
4.无意义的token似乎更难记一些, 可以用有意义的试试<br>

复制任务,在窗口内<br>
llama2-7b-chat后一半的正确率在70%~90%左右,无意义的token<br>

试试在PG-19上训练的模型<br>

## 22日
复制任务,在窗口内<br>
对于有意义的token序列，llama2-7b-chat后一半的正确率大部分都是100%， 这么一看，这个设置比较适合测试工作记忆长度<br>

对于在PG-19上从头训练一个epoch的小模型（80M）来说<br>
记忆随机序列的正确率为接近0%, 记忆有意义的序列的在一段区间内为100%<br>
模型在2048的segment上训练，这个区间为4~32，之后就慢慢下降，远远少于训练时的区间<br>
llama2-7b-chat的较高正确率有可能源于语言建模的任务，而这样随机的token序列设置更接近“死记硬背”的工作记忆长度<br>

补充一下，我为什么要执着于不用copy task训练，因为即使在copy task能测出模型工作记忆长度的潜力，但不代表它在正常任务下仍能够有这么长的工作记忆<br>

可以计算语言建模的准确率对比一下，看看记忆（history）的增益
如果前面有没有这个信息准确率都不变，说明根本没在记忆

ok,语言建模的准确率和复制的准确率在训练窗口内有明显变化, 在训练窗口外差距很小。
唯一可惜的是由于参数量较少，并没有达到100%的准确率。

